<!DOCTYPE html>
<html lang="en">
<head>
    <title>Kenny Lam - GSoC 2023</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>


    <!-- JavaScript Bundle with Popper -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css" integrity="sha512-SzlrxWUlpfuzQ+pcUCosxcglQRNAq/DZjVsC0lE40xsADsfeQoEypE+enwcOiGjk/bSuGGKHEyjSoQ1zVisanQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <!--    <link href="css/bootstrap.min.css" rel="stylesheet">-->
    <!--    <script src="js/bootstrap.bundle.min.js"></script>-->
    <script src="
https://cdn.jsdelivr.net/npm/echarts@5.4.1/dist/echarts.min.js
"></script>
</head>
<style>
    body, html {
        height: 100%;
        /*margin: 0;*/
        /*overflow: hidden*/
        position: relative;
        overflow: auto;
        scroll-behavior: smooth;
    }

    .nav-link {
        font-weight: 400;
        font-size: 15px;
        font-family: "Libre Franklin", "Helvetica Neue", helvetica, arial, sans-serif;
        line-height: 1.8;
        color: #C9C9C9FF;
    }

    .nav-item{
        font-weight: 400;
        font-size: 15px;
        font-family: "Libre Franklin", "Helvetica Neue", helvetica, arial, sans-serif;
        line-height: 1.8;
        color: #C9C9C9FF;
        padding: 5px;
    }

    .bgimg {
        position: relative;
        background-position: center;
        background-repeat: no-repeat;
        background-size: cover;
        background-image: url("index_bground.JPG");
        height: 100%;

    }

    .cover-text {
        font-family: "Libre Franklin", "Helvetica Neue", helvetica, arial, sans-serif;
        position: absolute;
        left: 0;
        top: 15%;
        width: 100%;
        text-align: center;
        color: #000000;
    }



    /* Popup container - can be anything you want */
    .popup {
        position: relative;
        display: inline-block;
        cursor: pointer;
        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
    }

    /* The actual popup */
    .popup .popuptext {
        visibility: hidden;
        width: 160px;
        background-color: #555;
        color: #fff;
        text-align: center;
        border-radius: 6px;
        padding: 8px 0;
        position: absolute;
        z-index: 1;
        bottom: -120%;
        left: 50%;
        margin-left: -80px;
    }

    /*.card-img-top {*/
    /*    max-height: 250px;*/
    /*    min-height: 150px;*/
    /*    object-fit: cover;*/
    /*}*/

    /* Popup arrow */
    .popup .popuptext::after {
        content: "";
        position: absolute;
        bottom: 100%;
        transform: rotate(180deg);
        left: 50%;
        margin-left: -5px;
        border-width: 5px;
        border-style: solid;
        border-color: #555 transparent transparent transparent;
    }

    /* Toggle this class - hide and show the popup */
    .popup .show {
        visibility: visible;
        opacity: 1;
        transition: visibility 0s linear 500ms, opacity 500ms;
    }

    .popup .hide {
        visibility: hidden;
        opacity: 0;
        transition: visibility 0s linear 500ms, opacity 500ms;
    }

    /*
     * Custom translucent site header
     */

    .site-header {
        background-color: rgba(0, 0, 0, .85);
        -webkit-backdrop-filter: saturate(180%) blur(20px);
        backdrop-filter: saturate(180%) blur(20px);
    }
    .site-header a {
        color: #999;
        transition: ease-in-out color .15s;
    }
    .site-header a:hover {
        color: #fff;
        text-decoration: none;
    }

    /*
     * Dummy devices (replace them with your own or something else entirely!)
     */

    .product-device {
        position: absolute;
        right: 10%;
        bottom: -30%;
        width: 300px;
        height: 540px;
        background-color: #333;
        border-radius: 21px;
        -webkit-transform: rotate(30deg);
        transform: rotate(30deg);
    }

    .product-device::before {
        position: absolute;
        top: 10%;
        right: 10px;
        bottom: 10%;
        left: 10px;
        content: "";
        background-color: rgba(255, 255, 255, .1);
        border-radius: 5px;
    }

    .product-device-2 {
        top: -25%;
        right: auto;
        bottom: 0;
        left: 5%;
        background-color: #e5e5e5;
    }
    .green-highlight, .pink-highlight, .yellow-highlight {
        -webkit-border-radius: 5px;
        -moz-border-radius: 5px;
        border-radius: 5px;
        padding-left: 3px;
    }
    .pink-highlight {
        background: #FFCCFF; /* Default color, all browsers */
    }

    .pink-highlight::selection {
        background: #FF99FF; /* Selection color, WebKit/Blink Browsers */
    }

    .pink-highlight::-moz-selection {
        background: #FF99FF; /* Selection color, Gecko Browsers */
    }


    /*
     * Extra utilities
     */

    .border-top { border-top: 1px solid #e5e5e5; }
    .border-bottom { border-bottom: 1px solid #e5e5e5; }

    .box-shadow { box-shadow: 0 .25rem .75rem rgba(0, 0, 0, .05); }

    .flex-equal > * {
        -ms-flex: 1;
        -webkit-box-flex: 1;
        flex: 1;
    }
    @media (min-width: 768px) {
        .flex-md-equal > * {
            -ms-flex: 1;
            -webkit-box-flex: 1;
            flex: 1;
        }
    }

    @media (min-width: 580px) {
        .navbar {
            height: 60px;
        }
    }

    .overflow-hidden { overflow: hidden; }

    th, td {
        padding: 5px;
    }

    table, th, td {
        border: 1px solid black;
    }
</style>
<style>
    a.anchor{display: block; position: relative; top: -70px; visibility: hidden;}
</style>
<body>

<nav class="navbar bg-dark navbar-expand-sm bg-body-tertiary sticky-top">
    <div class="container-fluid">
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav me-auto ms-auto">
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/kennylam8" target="_blank"><i class="fa-brands fa-github" style="color: white;font-size:35px"></i></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://www.linkedin.com/in/kenny-lam8/" target="_blank"><i class="fa-brands fa-linkedin" style="color: white;font-size:35px"></i></a>
                </li>
            </ul>
            <ul class="navbar-nav me-auto ms-auto">
                <li class="nav-item">
                    <a class="nav-link" href="../../index.html">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="../../index.html#about">About</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="../../index.html#experience_all">Experience</a>
                </li>
                <li class="nav-item">
                    <a href="../../index.html#projects" class="nav-link">Projects</a>
                </li>
                <li class="nav-item">
                    <a href="../../index.html#contact" class="nav-link">Contact</a>
                </li>
            </ul>
        </div>
    </div>
</nav>



<div class="container">
    <br/>
    <h1 id="google-summer-of-code-2023-br-differentiating-real-and-misaligned-introns-with-machine-learning">Google Summer of Code 2023: <br/> Differentiating Real and Misaligned Introns with Machine Learning</h1>
    <p><img src="https://img.shields.io/badge/licence-MIT-blue" alt="Static Badge">
        <img src="https://img.shields.io/badge/Python-3.10-orange" alt="Static Badge"></p>
    <p>To address issue that strict filters rejects most of the legitimate introns,
        we developed IntronOrNot (ION) - a machine learning to differentiate that predicts
        if the intron is real or misaligned. The model accepts coordinates, .bed, and .gtf file as input.
        The prediction script is easy to use and achieved comparable results
        to sequenced-based deep learning intron predictor. A standalone function
        that extracts intron from .gtf is also included.</p>

    <h1 id="work-done">Work Done</h1>
    <p>All the work done in this project including all the commits can be found at:
        <br/><a href="https://github.com/kennylam8/IntronOrNot/">https://github.com/kennylam8/IntronOrNot/</a><br/>
        <a href="https://github.com/EnsemblGSOC/IntronOrNot">https://github.com/EnsemblGSOC/IntronOrNot</a></p>

    <p>The latest commit as of the submission of the GSoC final evaluation is: <a href="https://github.com/EnsemblGSOC/IntronOrNot/commit/5db1ff6c72fa89a11e8d66d1d69bcd66188740eb">5db1ff6</a></p>
    <p>We documented the process of testing and building the model using Jupyter-Notebooks, all the notebooks can be found at the root directory of the Github repository</p>
    <h1 id="table-of-contents">Table of Contents</h1>
    <ul>
        <li><a href="#organisation">Organisation &amp; Mentors</a></li>
        <li><a href="#getting-started">Getting Started</a><ul>
            <li><a href="#usage">Usage</a></li>
        </ul>
        </li>
        <li><a href="#background">Background</a><ul>
            <li><a href="#goal">Project Goal</a></li>
        </ul>
        </li>
        <li><a href="#training-set">Training Set Preparation</a><ul>
            <li><a href="#pos-trainset">Positive Class Data</a></li>
            <li><a href="#neg-trainset">Negative Class Data</a></li>
        </ul>
        </li>
        <li><a href="#feature-eng">Feature Engineering</a><ul>
            <li><a href="#feature-tested">Features Tested</a></li>
            <li><a href="#feature-selection">Feature Selection</a></li>
        </ul>
        </li>
        <li><a href="#ml-model">Machine Learning Model</a><ul>
            <li><a href="#model-arc">Model Architecture</a></li>
            <li><a href="#hyperparam-opt">Hyperparameter Optimisation</a></li>
            <li><a href="#model-training">Training</a></li>
            <li><a href="#model-eval">Evaluation Metrics</a></li>
            <li><a href="#shap">Feature Importance using SHAP (SHapley Additive exPlanations)</a></li>
            <li><a href="#pred-expl">Prediction Explanation</a></li>
        </ul>
        </li>
        <li><a href="#results">Results</a><ul>
            <li><a href="#cross-val">10-Fold Stratified Cross Validation</a></li>
            <li><a href="#external-val">External Validation &amp; Benchmark</a></li>
            <li><a href="#test-summary">Summary</a></li>
        </ul>
        </li>
        <li><a href="#challenges-limitation-and-future-work">Challenges, Limitations, and Future Work</a></li>
        <li><a href="#conclusion">Conclusion</a></li>
        <li><a href="#remarks">Acknowledgements and Remarks</a></li>
    </ul>
    <a class="anchor" id="organisation"></a>
    <h1>Organisation &amp; Mentors</h1>
    <p>Genome Assembly and Annotation (European Bioinformatics Institute / EMBL-EBI)</p>
    <h3 id="research-group">Research Group</h3>
    <p>Ensembl - <a href="https://www.ebi.ac.uk/about/teams/genome-interpretation/">Genome Interpretation Teams</a></p>
    <h3 id="mentors">Mentors</h3>
    <p><a href="https://www.ebi.ac.uk/people/person/jose-manuel-gonzalez-martinez/">Jose Gonzalez</a><br/>
        <a href="https://www.ebi.ac.uk/people/person/jonathan-mudge/">Jonathan Mudge</a><br/>
        <a href="https://www.ebi.ac.uk/people/person/adam-frankish/">Adam Frankish</a></p>
    <h1 id="graphical-abstract" >Graphical Abstract</h1>
    <p><img src="gsoc-2023-imgs/ga.png" style="height: auto; width: 100%" alt=""></p>
    <p style="text-align: right;">Created with BioRender.com</p>
    <br/>
    <h1><a class="anchor" id="getting-started"></a>Getting Started</h1>
    <h3 id="installation">Installation</h3>
    <ul>
        <li>Download the latest zipped script in <code>Releases</code></li>
        <li>Install the required dependencies detailed below</li>
    </ul>
    <h3 id="-a-name-enviroment-a-environment"><a class="anchor" id="enviroment"></a>Environment</h3>
    <ul>
        <li>32 GB of RAM or more is required for a large .bed file</li>
        <li>Multi-thread support is default to enabled with the Pandarallel library</li>
    </ul>
    <h3 id="-a-name-package-req-a-package-requirements"><a class="anchor" id="package-req"></a>Package Requirements</h3>
    <p><strong>Please Note that this requirement is for the final ION script in <code>Releases</code>, not the notebooks</strong>\
        <br/>
        biopython==1.81<br/>
        matplotlib==3.5.2<br/>
        numpy==1.25.0<br/>
        pandarallel==1.6.5<br/>
        pandas==2.0.3<br/>
        pyBigWig==0.3.22<br/>
        pyfaidx==0.7.2.1<br/>
        scikit_learn==1.1.1<br/>
        shap==0.41.0<br/>
        tqdm==4.64.0<br/>
        xgboost==1.6.2</p>
    <p><strong>Please Note that this requirement is for the ION script in <code>Releases</code>, not the notebooks</strong>\</p>
    <h2 id="-a-name-usage-a-usage"><a class="anchor" id="usage"></a>Usage</h2>
    <p>Coordinate mode (1-based):</p>
    <code>python3 ION.py --mode high-precision --type coord chr3 83979030 83990643 +</code>

    <p><br/>BED mode:</p>
    <code> python3 ION.py --mode high-precision --type bed --file examples/example.bed</code>
    <p><br/>GTF mode:</p>
    <code>python3 ION.py --mode high-precision --type gtf --file examples/example.gtf</code>
    <p><br/>IMPORTANT: ION can only evaluate intorns with canonical splice-site (GT:AG, GC:AG, AT:AC)</p>
    <h1 id="-a-name-background-a-background"><a class="anchor" id="background"></a>Background</h1>
    <p>Understanding the impact of genetic variation on disease requires comprehensive gene annotation.
        Human genes are well characterised following more than two decades of work on their annotation, however,
        we know that this annotation is not complete and that new experimental methods are generating data
        to help us towards the goal of complete gene annotation.</p>
    <p>The advancement in the accuracy of long-read sequencing technology has allowed us to explore novel transcript variants of known genes.
        Preventing potentially wrong transcripts and gene annotation is essential to the science community as many rely on the annotation for decision-making.
        Automated workflow with a has been developed to minimise the time needed to verify and annotated those transcript variants. However,
        current workflows are developed using a very strict rule-set and hence many of the novel transcript variants were rejected.
        This project aims to address this issue by using machine learning to differentiate good quality but rejected transcripts,
        using it as a standalone classification filter or analysing the decision-making methods of the model and consequently
        improving the rule-set used in the automated workflow.</p>
    <p>You can read more about the background of this project at: <a href="https://github.com/jmgonzmart/GSoC_ML_gene_annot">https://github.com/jmgonzmart/GSoC_ML_gene_annot</a></p>
    <h2 id="-a-name-goal-a-project-goal"><a class="anchor" id="goal"></a>Project Goal</h2>
    <p>This project consists of the following deliverables and goals:</p>
    <ul>
        <li>Install/prepare the environment and repository for the project.</li>
        <li>Extract the GENCODE annotation data and featurize them into tabular format.</li>
        <li>Explore the addition of other features that might facilitate decision-making or machine learning
            model.</li>
        <li>Learn to generate an extended set of low-quality transcript or splice junction predictions.</li>
        <li>Develop a machine learning model that differentiate misaligned and real introns. The model should have low false positive rate.</li>
        <li>Perform and document the statistical analysis of the model to extract its most relevant features for
            decision-making.</li>
        <li>Run the final model on novel transcripts and produce a detailed report of the results.</li>
    </ul>
    <h1 id="-a-name-training-set-a-training-set-preparation"><a class="anchor" id="training-set"></a>Training Set Preparation</h1>
    <h2 id="-a-name-pos-trainset-a-positive-class-data"><a class="anchor" id="pos-trainset"></a>Positive Class Data</h2>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/01_extract_introns_from_gencode.ipynb">01</a></p>
    <p>We used the GENCODE v44 (<a href="https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/">https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/</a>) as our positive set. We
        used a script to extract all the introns out of the .gtf file.</p>
    <h2 id="-a-name-neg-trainset-a-negative-class-data"><a class="anchor" id="neg-trainset"></a>Negative Class Data</h2>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/02_extract_negative_introns.ipynb">02</a>, <a href="https://github.com/kennylam8/IntronOrNot/blob/main/03_generating_false_introns.ipynb">03</a>, <a href="https://github.com/kennylam8/IntronOrNot/blob/main/04_combining_positive_and_negative_train_set.ipynb">04</a></p>
    <p>We used two source for generating negative class data.</p>
    <ul>
        <li><p>We have access to a previous gene annotators&#39; manually reviewed data, the dataset contains ~11000 introns, after removing introns that are already accepted in current version, 403 negative introns were obtained.</p>
        </li>
        <li><p>To simulate how false intron data could be presented in real data, we ultilized <a href="https://academic.oup.com/nargab/article/4/4/lqac092/6855700">PBSIM3</a> (Ono et al., 2022), a simulator for long-read sequencers that
            is capable to simulate both PacBio RS II continuous long reads (CLR) and Oxford Nanopore Technology (ONT) reads. We simulated the reads using GENCODE v44 <code>Long non-coding RNA transcript sequences</code> and <code>Protein-coding transcript sequences</code> RNA data. We simulated them using four different settings:</p>
            <ul>
                <li>ONT single pass - protein coding genes</li>
                <li>ONT multi-pass - protein coding genes</li>
                <li>PacBio Iso-seq - protein coding genes</li>
                <li>ONT single pass - lcnRNA</li>
            </ul>
        </li>
    </ul>
    <p>The reads were then aligned to the human genome respectively using <a href="https://doi.org/10.1093/bioinformatics/bty191">Minimap2</a> (Li, 2018), and intronic regions of all alignments were then extracted and
        compared against the current GENCODE annotation and those that were not in the current GENCODE annotation is treated as false/misaligned introns.
        About 110,000 false introns were obtained.</p>
    <h1 id="-a-name-feature-eng-a-feature-engineering"><a class="anchor" id="feature-eng"></a>Feature Engineering</h1>
    <h2 id="-a-name-feature-tested-a-features-tested"><a class="anchor" id="feature-tested"></a>Features Tested</h2>
    <p>9 categories of features were generated:</p>
    <ul>
        <li>Recount3 score: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/05_trainset_recount3_feature.tsv">Notebook 05</a><ul>
            <li>Based on the data extracted from the intronic region of <code>recount3: summaries and queries for large-scale RNA-seq expression and splicing</code> (Wilks et al.)</li>
        </ul>
        </li>
        <li>Repeat region: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/06_trainset_repeat_feature.tsv">Notebook 06</a><ul>
            <li>Check if any of the splice-sites lies in repeating regions.</li>
        </ul>
        </li>
        <li>Antisense Exon: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/07_trainset_antisense_feature.tsv">Notebook 07</a></li>
        <li>Distance of next nearest existing splice-site: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/09_trainset_nearest_alt_ss_dist_feature">Notebook 09</a><ul>
            <li>Check the coordinate of both the donor and acceptor splice-site against current annotation (GENCODE v44) and calculate the distance between the splice site and the closest annotated splice-site nearby (excluding exact match).</li>
        </ul>
        </li>
        <li>MaxEntScan score: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/10_trainset_MaxEntScan_feature.tsv">Notebook 10</a><ul>
            <li>Based on the script/methodology developed by Yeo and Burge - <code>Maximum entropy modeling of short sequence motifs with applications to RNA splicing signals</code></li>
        </ul>
        </li>
        <li>Basic sequence based feature: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/11_trainset_basic_features.tsv">Notebook 11</a><ul>
            <li>Calculates the GC content.</li>
            <li>Determines whether the sequence can be considered a CpG island based on the ratio of CpG dinucleotides and the GC content in the sequence.</li>
            <li>Calculates the intron length.</li>
        </ul>
        </li>
        <li>Conservation scores: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/12_trainset_conservation_scores_feature.tsv">Notebook 12</a><ul>
            <li>Calculate the splice-site conservation scores with the <a href="https://doi.org/10.1101/gr.3715005">PhastCon</a> and <a href="https://doi.org/10.1101%2Fgr.097857.109">PhyloP</a> conservation resources downloaded from the <a href="https://doi.org/10.1093%2Fbib%2Fbbs038">UCSC genome browser</a>.</li>
        </ul>
        </li>
        <li>Splice-site with better Recount3 score nearby: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/13_recount3_near_ss_with_better_score_feature.tsv">Notebook 13</a><ul>
            <li>We look at 5nt further at both direction of the splice-site and see if there is a splice-site recorded in recount3 that has a better score</li>
        </ul>
        </li>
        <li>Branch Point Prediction (BPP) score: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/14_trainset_BPP_score_feature.tsv">Notebook 14</a><ul>
            <li>Branch point prediction using <a href="https://doi.org/10.1093/bioinformatics/btx401">BPP</a> (Zhang el al.)</li>
        </ul>
        </li>
    </ul>
    <h2 id="-a-name-feature-selection-a-feature-selection"><a class="anchor" id="feature-selection"></a>Feature Selection</h2>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/17_feature_selection.ipynb">17</a></p>
    <p>To make the model easier to interpret, and improve its performance. We simplify the model using feature selection.</p>
    <p>We intentionally drop some features that we learned from empirical knowledge from the annotators are unimportant, namely the strand and chromosome of the introns.</p>
    <p>We performed feature selection using RFECV:
        Recursive Feature Elimination with Cross-Validation (RFECV) is a feature selection technique that aims to identify
        a subset of features that are most useful for making accurate predictions. It is an extension of Recursive Feature
        Elimination (RFE), which eliminates feature one by one according to their validation performance, RFECV incorporates
        cross-validation (5-fold were chosen) for evaluation.</p>
    <p>We also dropped the <code>sc</code> feature which is generated by the BPP script, as it has relatively less importance (reflected by the RFECV result) and not easily interpretable, and also introns lesser than certain length could not obtain the <code>sc</code> feature, we decided to remove it. </p>
    <p>24 features were chosen. Refer to the second last cell of <a href="https://github.com/kennylam8/IntronOrNot/blob/main/17_feature_selection.ipynb">Notebook 17</a> for more details.</p>
    <h1 id="-a-name-ml-model-a-machine-learning-model"><a class="anchor" id="ml-model"></a>Machine Learning Model</h1>
    <h2 id="-a-name-model-arc-a-model-architecture"><a class="anchor" id="model-arc"></a>Model Architecture</h2>
    <p>We have tested different model architecture including Explainable Boosting Machine (EBM), RandomForest (RF), and more. We
        chose XGBoost as the model for this task for its good performance in internal validation.</p>
    <h2 id="-a-name-hyperparam-opt-a-hyperparameter-optimisation"><a class="anchor" id="hyperparam-opt"></a>Hyperparameter Optimisation</h2>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/18_hyperparameter_optimisation.ipynb">18</a></p>
    <p>We chose the hyperparameter the XGBoost model using exhaustive grid searching with 3-fold cross-validation of the following parameter:</p>
    <pre><code>parameter_grid = {
    <span class="hljs-string">'n_estimators'</span>: [<span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">150</span>, <span class="hljs-number">200</span>],
    <span class="hljs-string">'learning_rate'</span>: [<span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>],
    <span class="hljs-string">'max_depth'</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>],
    <span class="hljs-string">'min_child_weight'</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>],
    <span class="hljs-string">'subsample'</span>: [<span class="hljs-number">0.8</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">1.0</span>],
    <span class="hljs-string">'colsample_bytree'</span>: [<span class="hljs-number">0.8</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">1.0</span>]
}
</code></pre><p>The best parameters were combinations with <code>learning_rate = 0.1</code>, however after consideration our model has limited
    training data, a learning rate with 0.1 will have a potential problem of overwriting, after evaluating different
    combinations with internal validation, we opted to use <code>{&#39;colsample_bytree&#39;: 0.9, &#39;learning_rate&#39;: 0.01, &#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 1, &#39;n_estimators&#39;: 200, &#39;subsample&#39;: 0.8}</code>,
    which is the highest combination with <code>learning_rate = 0.01</code>.</p>
    <h2 id="-a-name-model-training-a-training"><a class="anchor" id="model-training"></a>Training</h2>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/19a_standard_model_building.ipynb">19a</a>, <a href="https://github.com/kennylam8/IntronOrNot/blob/main/19b_strict_model_building.ipynb">19b</a></p>
    <p>We trained three separate model with the same parameter except for the <code>scale_pos_weight</code>. According to the xgboost
        documentation, it &quot;control the balance of positive and negative weights, useful for unbalanced classes. A typical value
        to consider: sum(negative instances) / sum(positive instances)&quot;, after internal cross-validation, we settled on: </p>
    <ul>
        <li><strong>High-Recall Mode</strong><ul>
            <li><code>scale_pos_weight = sum(negative instances) / sum(positive instances)</code></li>
        </ul>
        </li>
        <li><strong>Standard Mode</strong><ul>
            <li><code>scale_pos_weight = sum(negative instances) / sum(positive instances) / 2</code></li>
        </ul>
        </li>
        <li><strong>High-Precision Mode</strong><ul>
            <li><code>scale_pos_weight = sum(negative instances) / sum(positive instances) / 4</code></li>
        </ul>
        </li>
    </ul>
    <h2 id="-a-name-model-eval-a-evaluation-metrics"><a class="anchor" id="model-eval"></a>Evaluation Metrics</h2>
    <p>The model&#39;s performance should be evaluated using metrics that consider both classes, metrics such as MCC should be emphasised.
        We will evaluate our model using these metrics:</p>
    <ul>
        <li>Matthews Correlation Coefficient (MCC)</li>
        <li>Accuracy (Acc)</li>
        <li>Balanced Accuracy (BAcc)</li>
        <li>Precision</li>
        <li>Recall</li>
        <li>False Positive Rate (FPR)<ul>
            <li>This is espicially important because we need to ensure the model does not produce false positive</li>
        </ul>
        </li>
        <li>Area Under Receiver Operating Characteristic Curve (AUROC)</li>
    </ul>
    <h2 id="-a-name-shap-a-feature-importance-using-shap-shapley-additive-explanations-"><a class="anchor" id="shap"></a>Feature Importance using SHAP (SHapley Additive exPlanations)</h2>
    <p>One of the primary objectives of this project is to gain a deeper understanding of the significance of various features,
        knowledge that could be leveraged to enhance existing filters. Gaining insights into the model&#39;s performance is not merely beneficial but crucial.
        A more interpretable model could substantially contribute to more informed and effective decision-making processes.</p>
    <p>We sampled 50% of the data (~240k entries) to examine the overall importance of features and how the value of features are affecting the model.\
        The color reflects the value of the feature, the order of the features (vertically) is the importance of it, and the x-axis reflects
        the impact on the model (SHAP value).</p>
    <p><img src="gsoc-2023-imgs/shap_comparison.png" style="height: auto; width: 100%" alt="">
        <img src="gsoc-2023-imgs/shap_comparison_2.png" style="height: auto; width: 100%" alt="">
        We can see that recount3 score is the most important feature and from the first plot we can see that the model
        definitely favours entries with high recount3 score. One interesting finding is that phyloP or the phastCon score
        is also an important feature, as it was not incorporated in the original filters used by the annotation team, this
        could also be considered.</p>
    <h2 id="-a-name-pred-expl-a-prediction-explanation"><a class="anchor" id="pred-expl"></a>Prediction Explanation</h2>
    <p>You can export and view the explanation for the prediction using <code>--shap true</code> option, it is also defaulted to true in coordinates mode</p>
    <h3 id="example-plot-">Example plot:</h3>
    <p><img src="gsoc-2023-imgs/example_waterfall_explanation.png" style="height: auto; width: 100%" alt=""></p>
    <h1 id="-a-name-results-a-results"><a class="anchor" id="results"></a>Results</h1>
    <p>Relevant Notebook: <a href="https://github.com/kennylam8/IntronOrNot/blob/main/20a_external_benchmarking.ipynb">20a</a>, <a href="https://github.com/kennylam8/IntronOrNot/blob/main/20b_external_benchmarking_gencode.ipynb">20b</a></p>
    <h2 id="-a-name-cross-val-a-10-fold-stratified-cross-validation"><a class="anchor" id="cross-val"></a>10-Fold Stratified Cross Validation</h2>
    <p>Standard Deviation (SD) of the folds are presented as the value after ±, only the first s.f. are shown in SD.</p>
    <table>
        <thead>
        <tr>
            <th></th>
            <th>Accuracy</th>
            <th>B. Accuracy</th>
            <th>FPR</th>
            <th>MCC</th>
            <th>AUROC<sub>score</sub></th>
            <th>Precision</th>
            <th>Recall</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>ION (High-Recall Mode)</td>
            <td>0.949</td>
            <td>0.937</td>
            <td>0.083</td>
            <td>0.836</td>
            <td>0.980</td>
            <td>0.982</td>
            <td>0.956</td>
        </tr>
        <tr>
            <td>ION (Standard Mode)</td>
            <td>0.933</td>
            <td>0.933</td>
            <td>0.068</td>
            <td>0.800</td>
            <td>0.980</td>
            <td>0.984</td>
            <td>0.933</td>
        </tr>
        <tr>
            <td>ION (High-Precision Mode)</td>
            <td>0.894</td>
            <td>0.917</td>
            <td>0.046</td>
            <td>0.722</td>
            <td>0.980</td>
            <td>0.989</td>
            <td>0.881</td>
        </tr>
        </tbody>
    </table>
    <p>We can see that adjusting the <code>scale_pos_weight</code> parameter of the model allows us to lower to FPR (while sacrificing the overall predictive performance (indicated by MCC and Recall))</p>
    <h2 id="-a-name-external-val-a-external-validation-benchmark"><a class="anchor" id="external-val"></a>External Validation &amp; Benchmark</h2>
    <h3 id="manually-annotated-lncrna-test-set">Manually annotated lncRNA test-set</h3>
    <table>
        <thead>
        <tr>
            <th></th>
            <th>Acc</th>
            <th>B. Acc</th>
            <th>FPR</th>
            <th>MCC</th>
            <th>AUROC<sub>score</sub></th>
            <th>Precision</th>
            <th>Recall</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>ION (High-Recall Mode)</td>
            <td><strong>0.860</strong></td>
            <td>0.724</td>
            <td>0.443</td>
            <td><strong>0.361</strong></td>
            <td><strong>0.858</strong></td>
            <td>0.952</td>
            <td><strong>0.890</strong></td>
        </tr>
        <tr>
            <td>ION (Standard Mode)</td>
            <td>0.742</td>
            <td><strong>0.784</strong></td>
            <td>0.165</td>
            <td>0.351</td>
            <td>0.851</td>
            <td>0.978</td>
            <td>0.732</td>
        </tr>
        <tr>
            <td>ION (High-Precision Mode)</td>
            <td>0.429</td>
            <td>0.673</td>
            <td><strong>0.028</strong></td>
            <td>0.210</td>
            <td>0.855</td>
            <td><strong>0.992</strong></td>
            <td>0.374</td>
        </tr>
        <tr>
            <td>Filters (Intropolis)</td>
            <td>0.366</td>
            <td>0.633</td>
            <td>0.040</td>
            <td>0.171</td>
            <td>0.633</td>
            <td>0.987</td>
            <td>0.306</td>
        </tr>
        <tr>
            <td>Filters (Recount3)</td>
            <td>0.701</td>
            <td>0.654</td>
            <td>0.403</td>
            <td>0.191</td>
            <td>0.654</td>
            <td>0.946</td>
            <td>0.711</td>
        </tr>
        <tr>
            <td>SPLAM<sup>1</sup></td>
            <td>0.483</td>
            <td>0.674</td>
            <td>0.091</td>
            <td>0.205</td>
            <td>0.831</td>
            <td>0.674</td>
            <td>0.674</td>
        </tr>
        </tbody>
    </table>
    <ol>
        <li>True if both Donor score and Acceptor score &gt;= 0.5 else false, actual predicted value is calculated by using the min(donor_score, acceptor_score).</li>
    </ol>
    <h3 id="gencode-v46-newly-added-introns">GENCODE v46 Newly Added Introns</h3>
    <p>As only single class is available (accepted/positive), only accuracy is included</p>
    <table>
        <thead>
        <tr>
            <th></th>
            <th>Accuracy</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>ION (High-Recall mode)</td>
            <td><strong>0.844</strong></td>
        </tr>
        <tr>
            <td>ION (Standard Mode)</td>
            <td>0.708</td>
        </tr>
        <tr>
            <td>ION (High-Precision Mode)</td>
            <td>0.601</td>
        </tr>
        <tr>
            <td>SPLAM<sup>1</sup></td>
            <td>0.772</td>
        </tr>
        </tbody>
    </table>
    <ol>
        <li>True if both Donor score and Acceptor score &gt;= 0.5 else false</li>
    </ol>
    <h2 id="-a-name-test-summary-a-summary"><a class="anchor" id="test-summary"></a>Summary</h2>
    <p>Table 1 provides a comparative evaluation of different machine learning models designed to classify long non-coding
        RNAs (lncRNAs) based on a manually annotated test set. Among the models, ION in High-Recall Mode stands out for its superior
        performance across multiple metrics: it boasts the highest accuracy (0.860), Matthews Correlation Coefficient (0.361), and
        AUROC score (0.858). It also excels in recall with a rate of 0.890, suggesting that it is particularly effective at correctly
        identifying positive cases. However, this high recall comes at the expense of a higher False Positive Rate (FPR) of 0.443,
        indicating that the model also incorrectly classifies a considerable number of negative cases as positive.
    </p>
    <p>ION in Standard Mode achieves the highest Balanced Accuracy of 0.784 and maintains a relatively low FPR of 0.165,
        offering a balanced performance between sensitivity and specificity. ION in High-Precision Mode excels in precision
        with a score of 0.992 and has the lowest FPR of 0.028, but lags in recall and overall accuracy. Filters (Intropolis)
        and Filters (Recount3) generally perform lower across most metrics, while SPLAM<sup>1</sup> shows moderate results.
        Each model appears to have its strengths and weaknesses, providing options to choose based on the specific requirements
        of an lncRNA classification task.</p>
    <p>Table 2 provides comparison of models. As only accepted data are available in GENCODE, we can only compare their accuracy,
        we can see that the high-recall mode of ION has the best accuracy, while other both the standard and high-precision mode suffered
        from relatively low accuracy compared to SPLAM, which achieved 77.2%.</p>
    <h1 id="-a-name-challenges-limitation-and-future-work-a-challenges-limitations-and-future-work"><a class="anchor" id="challenges-limitation-and-future-work"></a>Challenges, Limitations, and Future Work</h1>
    <p>There are numerous challenges in this project. Most notably is the imbalance of the training data, as the majority of the data
        are obtained by extracting introns from annotation, this makes the majority of the train-set "positive". This causes a huge
        problem at the beginning, although we dampen it with the generation of false data, the ration of positive vs negative is still
        around 4:1, a better model could be built with the generation of more false introns, presumably sets accumulated by annotators
        or a more comprehensive simulation of introns using the method utilised in this project.</p>
    <p>The performance of the machine learning model is limited to the training data, although recount3 is the most comprehensive dataset available to this data,
        in the future, model should be retrained and adjusted in accordance to the newer data.</p>
    <p>ION is built on many experimental and empirical data, like recount3 score, repeat regions, and conservation scores. On the other hand, there are
        tools that predicts introns using the sequence alone, such as SpliceAI and SPLAM. Future work could expan on integrating both sequence-based
        intron prediction and experimental data. Additionally, the recent development in protein structure predict might allow us to incorporate structural
        prediction of the actual protein (analysis the legitimacy of introns using the final structure of the protein).</p>
    <h1 id="-a-name-conclusion-a-conclusion"><a class="anchor" id="conclusion"></a>Conclusion</h1>
    <p>We have successfully developed a model ION that predicts the legitimacy of an intron. The performance of ION is comparable
        to deep learning methods such as SpliceAI and SPLAM, while still being interpretable. This would allow annotators and users
        to use this program to evaluate introns and understand the decision behind it. Many improvements could be make to improve
        this model including generating higher quality &quot;negative&quot; introns and further tuning and experimenting with other features and models.</p>
    <h1 id="-a-name-remarks-a-acknowledgements-and-remarks"><a class="anchor" id="remarks"></a>Acknowledgements and Remarks</h1>
    <p>I am truly grateful for the unwavering support I&#39;ve received throughout the course of this project from the mentors.
        Despite an initial slow start, my mentors have been incredibly supportive, providing invaluable guidance
        through daily communication and during our regular meetings.</p>
    <p>From the moment I was accepted into the program to its near completion, I have been continually awed and humbled by the
        wealth of knowledge and skills I&#39;ve gained through this experience. My primary focus has traditionally been in the realm
        of computational bio/chemistry, which made the opportunity to delve into an unfamiliar domain through this
        project all the more exhilarating for me.</p>

</div>

</body>
</html>